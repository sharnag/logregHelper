---
title: "logregHelper"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{logregHelper}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(logregHelper)
```

This vignette provides an overview of the logregHelper package and it's key functions.

The purpose of this package is to simplify and streamline the model selection process by providing insightful summaries, tables and visualisations that allow users to review and compare logistic regression models. This package focuses on two areas: Model Diagnostics and Model Selection.

The package can be installed from Github using:
```{r, eval=FALSE}
install.packages("devtools")
devtools::install_github("sharnag/logregHelper")
```

There are currently two main functions in the package:

**Model Diagnostics**

- `plotPredictors` plots the logit of the response variable against the numerical predictors

**Model Selection**

- `viewCoef` view the estimated coefficients and confidence intervals

In this vignette we will provide examples of how to use them.

The required inputs for the functions are fitted `glm` models of family "binomial". Currently `glm` models of other family types are not supported. 

In this vignette we will use models from the **mtcars** Motor Trend Car Road Tests dataset taken from the 1974 Motor Trend US magazine. The logistic regression task is to predict *am*; whether the transmission is automatic or manual. Source: `datasets` package.


# Model Diagnostics
## plotPredictors
Logistic regression assumes linearity between the logit of the response variable and the continuous predictors. The `plotPredictors` function assists in this inspection by plotting the numerical predictor against the logit of the response. Note: discrete predictors are also included. `plotPredictors` is an S3 method on `glm` type objects. It calls another S3 method `addCols` which returns a `data.frame` with the required columns.


To begin we first fit or load a `glm` object of family "binomial":
```{r}
fit1 <- glm(am ~ cyl + hp + wt, data=mtcars, family = binomial(link = "logit"))
```


By default, `plotPredictors` returns a list of `ggplot` objects which we can view separately:
```{r, warning=FALSE, fig.width=5, fig.height=4, fig.align='center'}
myPlots <- plotPredictors(fit1)
myPlots[[2]]
```

The smooth regression line can take a long time to run for models with large datasets (1000+ points). In this case we can disable the smoothing line with the `smooth` argument:
```{r, fig.width=5, fig.height=4, fig.align='center'}
myPlots <- plotPredictors(fit1, smooth=F)
myPlots[[2]]
```

Alternatively, we can return an interactive plot using:
```{r, fig.width=7, fig.height=4, fig.align='center'}
plotPredictors(fit1, interactive = T)
```

Currently there is no option to add a smoothing line to the interactive plot.

# Model Selection
## viewCoef
The `viewCoef` function returns the estimated coefficients and 95% confidence intervals from one or more fitted `glm` objects of family "binomial". It maybe useful to see how the estimated coefficients change based on different predictors in a model.

The default usage returns a `gt` table, however, you can also return the data as a `data.frame` by setting the argument `raw` to T.
```{r, warning=FALSE, message=FALSE}
viewCoef(fit1)
```
```{r, warning=FALSE, message=FALSE}
viewCoef(fit1, raw=T)
```

Other arguments include whether to exponentiate the coefficients (`exp`), change the number of significant figures (`sigfig`), and include the test statistic and p-value (`expand`). We can also change the confidence interval level (`ci`) and return standard confidence intervals based on asymptotic normality instead of the profile likelihood confidence intervals.

```{r, warning=FALSE, message=FALSE}
viewCoef(fit1, exp=T, sigfig = 3, expand=T, ci=0.9, ci_normal=T)
```


Additionally, we can compare two or more models by passing the `glm` objects in a list. 
```{r, warning=FALSE, message=FALSE}
fit2 <- glm(am ~ cyl + hp, data=mtcars, family = binomial(link = "logit"))
fit3 <- glm(am ~ cyl + wt, data=mtcars, family = binomial(link = "logit"))
viewCoef(list(fit1, fit2, fit3), sigfig=4)
```

Finally, we can return a Forest Plot of the estimates and confidence intervals using:
```{r, warning=FALSE, fig.width=7, fig.height=4, fig.align='center', message=FALSE}
viewCoef(list(fit1,fit2, fit3), plot=T) 
```


